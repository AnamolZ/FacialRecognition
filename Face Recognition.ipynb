{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "88890e0b-563c-4a4f-819f-bdbf0a539dff",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import cv2\n",
    "import face_recognition\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "import joblib\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2ccf9542-e560-4d9c-bce5-37292ad39191",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_face_encodings(directory):\n",
    "    face_encodings = []\n",
    "    names = []\n",
    "\n",
    "    for name in os.listdir(directory):\n",
    "        person_dir = os.path.join(directory, name)\n",
    "        if not os.path.isdir(person_dir):\n",
    "            continue\n",
    "\n",
    "        for image_file in os.listdir(person_dir):\n",
    "            image_path = os.path.join(person_dir, image_file)\n",
    "            image = face_recognition.load_image_file(image_path)\n",
    "            face_encodings_in_image = face_recognition.face_encodings(image)\n",
    "            if len(face_encodings_in_image) > 0:\n",
    "                face_encoding = face_encodings_in_image[0]\n",
    "                face_encodings.append(face_encoding)\n",
    "                names.append(name)\n",
    "\n",
    "    return face_encodings, names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f50887fb-b3e6-4044-8841-3de0528f7789",
   "metadata": {},
   "outputs": [],
   "source": [
    "def recognize_faces(frame, model, known_encodings, known_names, tolerance=0.6):\n",
    "    face_locations = face_recognition.face_locations(frame)\n",
    "    face_encodings = face_recognition.face_encodings(frame, face_locations)\n",
    "\n",
    "    recognized_names = []\n",
    "    for face_encoding in face_encodings:\n",
    "        distances = face_recognition.face_distance(known_encodings, face_encoding)\n",
    "        min_distance_idx = distances.argmin()\n",
    "        min_distance = distances[min_distance_idx]\n",
    "\n",
    "        if min_distance <= tolerance:\n",
    "            name = known_names[min_distance_idx]\n",
    "            recognized_names.append(name)\n",
    "        else:\n",
    "            recognized_names.append(\"Unknown Person\")\n",
    "\n",
    "    return recognized_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "cdcbc966-02c6-4ecb-b9ca-c0d028cebff6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def main():\n",
    "    image_directory = 'D:/Data Science/face_recognizer/training'\n",
    "    model_filename = 'D:/Data Science/face_recognizer/model/face_recognition_model.joblib'\n",
    "    face_detection_frequency = 144\n",
    "    distance_tolerance = 0.6\n",
    "    display_duration = 5\n",
    "\n",
    "    if os.path.exists(model_filename):\n",
    "        model_data = joblib.load(model_filename)\n",
    "        face_encodings, names = model_data['face_encodings'], model_data['names']\n",
    "    else:\n",
    "        face_encodings, names = load_face_encodings(image_directory)\n",
    "        model_data = {'face_encodings': face_encodings, 'names': names}\n",
    "        joblib.dump(model_data, model_filename)\n",
    "\n",
    "    model = KNeighborsClassifier(n_neighbors=3)\n",
    "    model.fit(face_encodings, names)\n",
    "\n",
    "    video_capture = cv2.VideoCapture(0)  # Use the default backend\n",
    "\n",
    "    # Set camera resolution to capture at 144 FPS\n",
    "    video_capture.set(cv2.CAP_PROP_FPS, 144)\n",
    "\n",
    "    frame_count = 0\n",
    "    recognized_names_start_time = None\n",
    "\n",
    "    while True:\n",
    "        ret, frame = video_capture.read()\n",
    "\n",
    "        if not ret:\n",
    "            print(\"Failed to capture frame.\")\n",
    "            break\n",
    "\n",
    "        frame_count += 1\n",
    "\n",
    "        frame = cv2.flip(frame, 1)\n",
    "\n",
    "        if frame_count % face_detection_frequency == 0:\n",
    "            recognized_names = recognize_faces(frame, model, face_encodings, names, distance_tolerance)\n",
    "\n",
    "            if not recognized_names:\n",
    "                recognized_names = [\"Unknown Person\"]\n",
    "\n",
    "            recognized_names_start_time = time.time()\n",
    "\n",
    "        if recognized_names_start_time is not None:\n",
    "            time_since_recognition = time.time() - recognized_names_start_time\n",
    "            if time_since_recognition <= display_duration:\n",
    "                for name in recognized_names:\n",
    "                    cv2.putText(frame, name, (50, 50), cv2.FONT_HERSHEY_SIMPLEX, 1, (0, 255, 0), 2, cv2.LINE_AA)\n",
    "            else:\n",
    "                recognized_names_start_time = None\n",
    "\n",
    "        cv2.imshow('Video', frame)\n",
    "\n",
    "        if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "            break\n",
    "\n",
    "    video_capture.release()\n",
    "    cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e68b930-4c1c-4d56-873f-b592a678428c",
   "metadata": {},
   "outputs": [],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29a092a1-6049-40fa-b447-18b86c2c5f40",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
